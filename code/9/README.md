This experiment aims to create an optimizer for an optimizer, i.e. is to tune Genetic Algorithm using Differential Evolution.

### Abstract

In this experiment we would be using Differential Evolution to optimize the parameters of GA which in turn tries to optimize DLTZ1,3,5,7 models over 2,4,6,8 objectives and 10,20,40 decisions. 
In other words we are trying to optimize an optimizer. We will be comparing the solutions generated by untuned GA (with default parameters) with the solution generated by tuned GA (with optimized parameters) and see if we actually achieve improvements.

### Introduction

> What is Genetic Algorithm (GA)?

Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. Many people, biologists included, are astonished that life at the level of complexity that we observe could have evolved in the relatively short time suggested by the fossil record. The idea with GA is to use this power of evolution to solve optimization problems.

Genetic Algorithms (GAs) are adaptive heuristic search algorithm based on the evolutionary ideas of natural selection and genetics. As such they represent an intelligent exploitation of a random search used to solve optimization problems. Although randomised, GAs are by no means random, instead they exploit historical information to direct the search into the region of better performance within the search space.

"Survival of the fittest" is the basic principle behind GA's. [1]

> Operators of GA

After an initial population is randomly generated, the algorithm evolves the through three operators:
* **Selection** which equates to survival of the fittest;
* **Crossover** which represents mating between individuals;
* **Mutation** which introduces random modifications.

> Parameters required by GA

* Population Size
* Number of Generations
* Crossover probability
* Mutation probability 

> What is Differential Evolution (DE) ?

Differential evolution optimizes a problem by maintaining a population of candidate solutions and creating new candidate solutions by combining existing ones according to a formula which depends on
 the variation of DE being used, and then keeping whichever candidate solution has the best score or fitness on the optimization problem at hand. It makes few or no assumptions about the problem being optimized and can search very large spaces of candidate solutions.

DE replaces the currently selected candidate immediately if the new candidate formed by extrapolation is better than it. Hence it doesn't need one to one comparison with each of the existing candidates to maintain best solutions. In this way it is much better than GA.

In this experiment we do the following
* Extrapolate from some candidate X, chosen at random.
* Add in values from one other extrapolation (Y-Z)
* DE is used to try and optimize the parameters of the GA to get better results for DTLZ5 with 10 decision values and 2 objective functions

### Implementation

1. The model used is DLTZ1 with 2 objectives and 10 decisions
2. Genetic Algorithm is developed to optimize the objectives of the above model. From the finally obtained frontier, the distance From Hell is calculated by finding the nearest neighbor in the baseline frontier and determining the distance between these points. The mean of all these distances is used as the 
aggregate score of the GA for comparison basis.
3. A model encompassing the GA parameters in written as follows. 

```python
  def ga(model, b_min, b_max, b_pop, num_can, num_gen, p_mut, p_cros):
    population_size = num_can
    generations = num_gen 
    p_crossover = p_cros 
    p_mutation = p_mut 
    total_decs = 10
    total_objs = 2
    base_min = b_min
    base_max = b_max
```

4. The Differential Evolution model is implemented which works on the GA candidates. It generates an
initial frontier of candidates, and then iterates over the number of repeats trying to mutate the parameters of configuration so as to obtain the maximum distance from Hell (farther points result in more optimized objectives). Type 1 and Type 2 comparators are used for 
candidate selection and early termination of DE.

5. The final result is the best GA configuration, with the corresponding distance value, and the final populated frontier of configurations ranked based on the distance metric.
6. The best configuration is fed into GA optimizer of DTLZ1, to find the resulting mean distance and the solution obtained is compared with the solution obtained from untuned GA with default parameters.

### Results


### Threats to validity
This experiment only tries to optimize inputs for a GA for a specific model (DTLZ5). The effect of running DE to try to optimize GA parameters for other models, number of decisions and objective functions is not known. Thus, it is possible that these results cannot be generalized. Due to the large computation time, the sample size was not very large and there might not have been enough information to make a valid judgement. I have used the Monte-Carlo method to calculate the hypervolume which relies on generating a large number of valid candidates and comparing them to the pareto frontier generated by my algorithm as opposed to using the true pareto frontier for comparison and validation. The reason for this is that it was not possible to find a dataset containing true pareto frontiers for all variations of the models and the Monte Carlo method provides a good approximation without running an exhaustive analysis on the entire search space. This can definitely result in some inaccuracy in the results.

### Future work
Future work will definitely involve improving the performance of the algorithm as a whole by introducing parallism for runs. DE for different models can also be run in parallel to generate different GA parameters as these are independent.Other work in this area can include improving the results for higher order DTLZ objective functions. The results can possibly be improved by performing some preprocessing with a less intensive algorithm and generating a somehwhat optimal initial population instead of randomly generating the initial population instead of tweaking the GA parameters. Another possible improvement is experimenting with different type1 operators.


### Conclusion
The experiment shows that Differential Evolution has indeed improved the quality of input parameters to the GA. This is because the algorithm keeps improving the pool of candidates when the neighbor energy is better than the current energy. When the underlying optimizer is run multiple times using DE we are able to achieve better results by tuning the input after each run. This can greatly reduce the running time of algorithm by reducing the number of generations and the size of candidate pools in most cases.

### References
[https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html](https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html)
