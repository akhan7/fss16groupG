This experiment aims to create an optimizer for an optimizer, i.e. is to tune Genetic Algorithm using Differential Evolution.

### Abstract

In this experiment we would be using Differential Evolution to optimize the parameters of GA which in turn tries to optimize DLTZ1,3,5,7 models over 2,4,6,8 objectives and 10,20,40 decisions. 
In other words we are trying to optimize an optimizer. We will be comparing the solutions generated by untuned GA (with default parameters) with the solution generated by tuned GA (with optimized parameters) and see if we actually achieve improvements.

### Introduction

> What is Genetic Algorithm (GA)?

Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. Many people, biologists included, are astonished that life at the level of complexity that we observe could have evolved in the relatively short time suggested by the fossil record. The idea with GA is to use this power of evolution to solve optimization problems.

Genetic Algorithms (GAs) are adaptive heuristic search algorithm based on the evolutionary ideas of natural selection and genetics. As such they represent an intelligent exploitation of a random search used to solve optimization problems. Although randomised, GAs are by no means random, instead they exploit historical information to direct the search into the region of better performance within the search space.

"Survival of the fittest" is the basic principle behind GA's. [1]

> Operators of GA

After an initial population is randomly generated, the algorithm evolves the through three operators:
* **Selection** which equates to survival of the fittest;
* **Crossover** which represents mating between individuals;
* **Mutation** which introduces random modifications.

> Parameters required by GA

* Population Size
* Number of Generations
* Crossover probability
* Mutation probability 

> What is Differential Evolution (DE) ?

Differential evolution optimizes a problem by maintaining a population of candidate solutions and creating new candidate solutions by combining existing ones according to a formula which depends on
 the variation of DE being used, and then keeping whichever candidate solution has the best score or fitness on the optimization problem at hand. It makes few or no assumptions about the problem being optimized and can search very large spaces of candidate solutions.

DE replaces the currently selected candidate immediately if the new candidate formed by extrapolation is better than it. Hence it doesn't need one to one comparison with each of the existing candidates to maintain best solutions. In this way it is much better than GA.

In this experiment we do the following
* Extrapolate from some candidate X, chosen at random.
* Add in values from one other extrapolation (Y-Z)
* DE is used to try and optimize the parameters of the GA to get better results for DTLZ5 with 10 decision values and 2 objective functions

### Implementation

1. The model used is DLTZ1 with 2 objectives and 10 decisions
2. Genetic Algorithm is developed to optimize the objectives of the above model. From the finally obtained frontier, the distance From Hell is calculated by finding the nearest neighbor in the baseline frontier and determining the distance between these points. The mean of all these distances is used as the 
aggregate score of the GA for comparison basis.
3. A model encompassing the GA parameters in written as follows. 

```python
  def ga(model, b_min, b_max, b_pop, num_can, num_gen, p_mut, p_cros):
    population_size = num_can
    generations = num_gen 
    p_crossover = p_cros 
    p_mutation = p_mut 
    total_decs = 10
    total_objs = 2
    base_min = b_min
    base_max = b_max
```

4. The Differential Evolution model is implemented which works on the GA candidates. It generates an
initial frontier of candidates, and then iterates over the number of repeats trying to mutate the parameters of configuration so as to obtain the maximum distance from Hell (farther points result in more optimized objectives). Type 1 and Type 2 comparators are used for 
candidate selection and early termination of DE.

5. The final result is the best GA configuration, with the corresponding distance value, and the final populated frontier of configurations ranked based on the distance metric.
6. The best configuration is fed into GA optimizer of DTLZ1, to find the resulting mean distance and the solution obtained is compared with the solution obtained from untuned GA with default parameters.

### Results
Genetic Algorithm's parameters have been tuned with the help of DE. As we'll see from the graphs below, the tuned GA performs significantly better as compared to the untuned GA.

#### Tuned GA (DTLZ 1)
The graph below shows the normalized hypervolume of the tuned GA tested with DTLZ 1 model. As the number of objectives decrease, the hypervolume also shows a significant increase. 

![DTLZ 1 Results](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/r1.jpeg)

Comparing the tuned vs untuned GA, we can see the significant increase of the hypervolume value for the tuned GA as compared to the untuned one.

![DTLZ 1 Comparison](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/e1.jpeg)

#### Tuned GA (DTLZ 3)
The graph below shows the normalized hypervolume of the tuned GA tested with DTLZ 3 model. What is surprising is the sharp increase of objective 4 20 decision value of hypervolume. The value of 2 Objective hypervolume is much higher than the other objectives. Testing with this model, the change in decision space doesn't seem to affect the performance of the GA.

![DTLZ 3 Results](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/r2.jpeg)

Comparing the tuned vs untuned GA, we can see the significant increase of the hypervolume value for the tuned GA as compared to the untuned one.

![DTLZ 3 Comparison](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/e2.jpeg)

#### Tuned GA (DTLZ 5)
The graph below shows the normalized hypervolume of the tuned GA tested with DTLZ 5 model. As the number of objectives decrease, the hypervolume also shows an increase. An interesting thing to observe is that the value 2 objective 40 decisions hypervolume is much higher than the other hypervolume values. The hypervolume values in Objective 2 only show variations with decision space, the higher objectives do not have a significant variation in their hypervolume values.

![DTLZ 5 Results](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/r3.jpeg)

Comparing the tuned vs untuned GA, it is surprising to see that in case of DTLZ 5 the untuned GA has performed better than the tuned GA. This is indicative of the probabilistic nature of these algorithms as sometimes even with tuning being done to the algorithms, unexpected results may arise.

![DTLZ 5 Comparison](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/e3.jpeg)

#### Tuned GA (DTLZ 7)
The graph below shows the normalized hypervolume of the tuned GA tested with DTLZ 7 model. In the case of DTLZ 7, the hypervolume values differ according to their decision space and not their objective space where they are fairly consistent. They have slight variations with lower decision values resulting in higher hypervolume values.

![DTLZ 7 Results](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/r4.jpeg)

Comparing the tuned vs untuned GA, the hypervolume for the tuned GA is higher than the untuned GA. But in constrast to the other models, here the variation in hypervolume value is not as significant as compared to DTLZ models 1, 3 and 5.

![DTLZ 7 Comparison](https://github.com/akhan7/fss16groupG/blob/master/code/9/image/e4.jpeg)

### Threats to validity
This experiment only tries to optimize inputs for a GA for a specific model (DTLZ5). The effect of running DE to try to optimize GA parameters for other models, number of decisions and objective functions is not known. Thus, it is possible that these results cannot be generalized. Due to the large computation time, the sample size was not very large and there might not have been enough information to make a valid judgement. I have used the Monte-Carlo method to calculate the hypervolume which relies on generating a large number of valid candidates and comparing them to the pareto frontier generated by my algorithm as opposed to using the true pareto frontier for comparison and validation. The reason for this is that it was not possible to find a dataset containing true pareto frontiers for all variations of the models and the Monte Carlo method provides a good approximation without running an exhaustive analysis on the entire search space. This can definitely result in some inaccuracy in the results.

The calculation of hypervolume requires construction of pareto frontier. As mentioned in the section III, the pareto frontier after running GA is built by taking individuals of the final generation and comparing with individuals from other generations. The pareto frontier is also cleaned to ensure that none of the elements in the frontier are dominated by the rest of the individuals of the frontier. During this process, the individuals are compared using "Type 1" comparator. This seems to be the bottleneck and affects the run time immensely. It takes close to 12 hours to run the entire experiment.

We use “boolean domination”, or commonly known as bdom, when comparing the individuals of a population. It is possible that sometimes a generation can contain individuals that do not dominate any other individual. In such a scenario it is hard to select fittest individuals in the population.

Aggregation methods combine the objectives into a scalar function that is used for fitness calculation. On the other hand, defining the goal function in this way requires profound domain knowledge that is often not available. We have used a pure aggregation method which is a sum of all the objective scores. This may not be the best aggregation in every case.

Consideration of metrics other than Hyper volume could lead to different results
Results may vary if other models are used for tuning the GA parameters
The efficiency of boolean domination in differentiating certain generations

### Future work
In the future we would like to improve the performance of the algorithm by improving the time complexity of the algorithm. We would also suggest including parallel running of processes to increase the efficiency. Also memory required for the algorithm can be optimized. Also we intend to improve the results by using CDOM instead of BDOM and by performing more experiments. 


### Conclusion
This experiment has enlightened us more about Genetic Algorithm and Differential Evolution as well as different topics around them. Thus, from our experiments, we conclude that Differential Evolution does improve the performance of a Genetic Algorithm. We also observed that generally if the objective space is less, the hypervolume is more.

### References
[https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html](https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html)
