This experiment aims to create an optimizer for an optimizer, i.e. is to tune Genetic Algorithm using Differential Evolution.

### Abstract

In this experiment we would be using Differential Evolution to optimize the parameters of GA which in turn tries to optimize DLTZ1,3,5,7 models over 2,4,6,8 objectives and 10,20,40 decisions. 
In other words we are trying to optimize an optimizer. We will be comparing the solutions generated by untuned GA (with default parameters) with the solution generated by tuned GA (with optimized parameters) and see if we actually achieve improvements.

### Introduction

> What is Genetic Algorithm?

Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. Many people, biologists included, are astonished that life at the level of complexity that we observe could have evolved in the relatively short time suggested by the fossil record. The idea with GA is to use this power of evolution to solve optimization problems.

Genetic Algorithms (GAs) are adaptive heuristic search algorithm based on the evolutionary ideas of natural selection and genetics. As such they represent an intelligent exploitation of a random search used to solve optimization problems. Although randomised, GAs are by no means random, instead they exploit historical information to direct the search into the region of better performance within the search space.

"Survival of the fittest" is the basic principle behind GA's. [1]

> Operators of GA

After an initial population is randomly generated, the algorithm evolves the through three operators:
* **Selection** which equates to survival of the fittest;
* **Crossover** which represents mating between individuals;
* **Mutation** which introduces random modifications.

> Parameters required by GA



### References
[https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html](https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol1/hmw/article1.html)
